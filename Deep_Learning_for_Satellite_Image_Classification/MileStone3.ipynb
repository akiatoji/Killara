{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning for Satellite Image Classification\n",
    "\n",
    "## Milestone 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from tensorflow.keras.layers import Concatenate, Conv2DTranspose\n",
    "from tensorflow.keras.models import Model\n",
    "from random import shuffle\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageDraw\n",
    "import numpy as np\n",
    "import json, os, glob\n",
    "import zipfile\n",
    "import shutil\n",
    "import rasterio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '/home/aki/ManningLiveProjects/2_Data/'\n",
    "MODELS_DIR = '/home/aki/ManningLiveProjects/3_Models/'\n",
    "\n",
    "shutil.rmtree(MODELS_DIR+'nwpu_images', ignore_errors=True)\n",
    "shutil.rmtree(MODELS_DIR+'nwpu_label_images', ignore_errors=True)\n",
    "os.mkdir(MODELS_DIR+'nwpu_label_images')\n",
    "os.mkdir(MODELS_DIR+'nwpu_label_images'+os.sep+'data')\n",
    "\n",
    "zipfile.ZipFile(DATA_DIR+'NWPU_images.zip', 'r').extractall(MODELS_DIR)\n",
    "os.rename(MODELS_DIR+'images', MODELS_DIR+'nwpu_images')\n",
    "\n",
    "subdirecs = [x[0] for x in os.walk(MODELS_DIR+'nwpu_images')][1:]\n",
    "to_delete = [s for s in subdirecs if 'lake' not in s]\n",
    "for k in to_delete:\n",
    "    shutil.rmtree(k, ignore_errors=True) \n",
    "os.rename(MODELS_DIR+'nwpu_images'+os.sep+'lake',MODELS_DIR+'nwpu_images'+os.sep+'data')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load multiple VGG-JSON into a dict.  Dict key is the image file name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_json_files = ['nwpu_lakes_30samples.json', 'nwpu_lakes_20samplesA.json', 'nwpu_lakes_20samplesB.json']\n",
    "\n",
    "image_files = {}\n",
    "for f in vgg_json_files:\n",
    "    image_files.update(json.load(open(DATA_DIR+'nwpu_labels/'+f)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add image data to dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aki/miniconda3/envs/liveproject/lib/python3.7/site-packages/rasterio/__init__.py:193: UserWarning: Dataset has no geotransform set.  Default transform will be applied (Affine.identity())\n",
      "  s.start()\n"
     ]
    }
   ],
   "source": [
    "for k, v in image_files.items():\n",
    "    img_data = rasterio.open(MODELS_DIR+'nwpu_images/data/'+k)\n",
    "    v['img_data'] = img_data.read().T\n",
    "    image_files[k] = v\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point image_files dict contains VGG_JSON (i.e. label) and image data.   This way you don't have to maintain two arrays with matching order like in the example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_region_data(regions):\n",
    "    X = []; Y = [] #pre-allocate lists to fill in a for loop\n",
    "    for k in regions: #cycle through each polygon\n",
    "        # get the x and y points from the dictionary\n",
    "        X.append(regions[k]['shape_attributes']['all_points_x'])\n",
    "        Y.append(regions[k]['shape_attributes']['all_points_y'])\n",
    "    return Y,X #image coordinates are flipped relative to json coordinates\n",
    "\n",
    "\n",
    "def write_mask(filename, filedata):\n",
    "    regions = filedata['regions']\n",
    "    X, Y = get_region_data(regions)\n",
    "    \n",
    "    # get the dimensions of the image\n",
    "    image_data = filedata['img_data']\n",
    "    nx, ny, nz = np.shape(image_data)\n",
    "    mask = np.zeros((ny,nx))\n",
    "    \n",
    "    for x,y in zip(X,Y):\n",
    "        # the ImageDraw.Draw().polygon function we will use to create the mask\n",
    "        # requires the x's and y's are interweaved, which is what the following\n",
    "        # one-liner does    \n",
    "        polygon = np.vstack((x,y)).reshape((-1,),order='F').tolist()\n",
    "        \n",
    "        # create a mask image of the right size and infill according to the polygon\n",
    "        if nx>ny:\n",
    "            x,y = y,x \n",
    "            img = Image.new('L', (ny, nx), 0)\n",
    "        elif ny>nx:\n",
    "            x,y = y,x \n",
    "            img = Image.new('L', (ny, nx), 0)            \n",
    "        else:\n",
    "            img = Image.new('L', (nx, ny), 0)\n",
    "        ImageDraw.Draw(img).polygon(polygon, outline=1, fill=1)\n",
    "        # turn into a numpy array\n",
    "        m = np.flipud(np.rot90(np.array(img)))\n",
    "        try:\n",
    "            mask = mask + m\n",
    "        except:\n",
    "            mask = mask + m.T\n",
    "    matplotlib.image.imsave(MODELS_DIR+'nwpu_label_images/data/'+filename+\"_mask.jpg\", mask.astype('uint8'))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename, filedata in image_files.items():\n",
    "    write_mask(filename, filedata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_batch_generator(files, batch_size = 32, sz = (512, 512)):\n",
    "  \n",
    "  while True: # this is here because it will be called repeatedly by the training function\n",
    "    \n",
    "    #extract a random subset of files of length \"batch_size\"\n",
    "    batch = np.random.choice(files, size = batch_size)    \n",
    "    \n",
    "    #variables for collecting batches of inputs (x) and outputs (y)\n",
    "    batch_x = []\n",
    "    batch_y = []\n",
    "    \n",
    "    #cycle through each image in the batch\n",
    "    for f in batch:\n",
    "\n",
    "        #preprocess the raw images \n",
    "        rawfile = f'nwpu_images/data/{f}'\n",
    "        raw = Image.open(rawfile)\n",
    "        raw = raw.resize(sz)\n",
    "        raw = np.array(raw)\n",
    "\n",
    "        #check the number of channels because some of the images are RGBA or GRAY\n",
    "        if len(raw.shape) == 2:\n",
    "            raw = np.stack((raw,)*3, axis=-1)\n",
    "        else:\n",
    "            raw = raw[:,:,0:3]\n",
    "            \n",
    "        #get the image dimensions, find the min dimension, then square the image off    \n",
    "        nx, ny, nz = np.shape(raw)\n",
    "        n = np.minimum(nx,ny)\n",
    "        raw = raw[:n,:n,:] \n",
    "            \n",
    "        batch_x.append(raw)\n",
    "        \n",
    "        #get the masks. \n",
    "        maskfile = rawfile.replace('nwpu_images','nwpu_label_images')+'_mask.jpg'\n",
    "        mask = Image.open(maskfile)\n",
    "        # the mask is 3-dimensional so get the max in each channel to flatten to 2D\n",
    "        mask = np.max(np.array(mask.resize(sz)),axis=2)\n",
    "        # water pixels are always greater than 100\n",
    "        mask = (mask>100).astype('int')\n",
    "        \n",
    "        mask = mask[:n,:n]\n",
    "\n",
    "        batch_y.append(mask)\n",
    "\n",
    "    #preprocess a batch of images and masks \n",
    "    batch_x = np.array(batch_x)/255. #divide image by 255 to normalize\n",
    "    batch_y = np.array(batch_y)\n",
    "    batch_y = np.expand_dims(batch_y,3) #add singleton dimension to batch_y\n",
    "\n",
    "    yield (batch_x, batch_y) #yield both the image and t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "prop_train = 0.5\n",
    "\n",
    "file_names = list(image_files.keys())\n",
    "split = int(prop_train * len(file_names))\n",
    "\n",
    "#split into training and testing\n",
    "train_files = file_names[0:split]\n",
    "test_files  = file_names[split:]\n",
    "\n",
    "train_generator = image_batch_generator(train_files, batch_size = batch_size)\n",
    "test_generator  = image_batch_generator(test_files, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 700 images belonging to 1 classes.\n",
      "Found 70 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1\n",
    "\n",
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "        featurewise_center=False,\n",
    "        featurewise_std_normalization=False,\n",
    "        shear_range=0,\n",
    "        zoom_range=0,\n",
    "        rotation_range=90,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "img_generator = train_datagen.flow_from_directory(\n",
    "        MODELS_DIR+'nwpu_images',\n",
    "        target_size=(128, 128),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None, seed=42, shuffle=False)\n",
    "\n",
    "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "        featurewise_center=False,\n",
    "        featurewise_std_normalization=False,    \n",
    "        shear_range=0,\n",
    "        zoom_range=0,\n",
    "        rotation_range=90,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "mask_generator = test_datagen.flow_from_directory(\n",
    "        MODELS_DIR+'nwpu_label_images',\n",
    "        target_size=(128, 128),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None, seed=42, shuffle=False)\n",
    "\n",
    "train_generator = (pair for pair in zip(img_generator, mask_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
